{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inpath = '/Users/Tom/python_projects/Memoire/Data/clean/6.5/presid_clean.csv'\n",
    "df = pd.read_csv(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Departement</th>\n",
       "      <th>Parti</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>ain</td>\n",
       "      <td>C</td>\n",
       "      <td>21.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>ain</td>\n",
       "      <td>D</td>\n",
       "      <td>19.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>ain</td>\n",
       "      <td>ED</td>\n",
       "      <td>16.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>ain</td>\n",
       "      <td>EG</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>ain</td>\n",
       "      <td>G</td>\n",
       "      <td>31.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year Departement Parti  Score\n",
       "0  1988.0         ain     C  21.21\n",
       "1  1988.0         ain     D  19.12\n",
       "2  1988.0         ain    ED  16.09\n",
       "3  1988.0         ain    EG  12.18\n",
       "4  1988.0         ain     G  31.41"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=['year', 'dep', 'Score_C', 'Score_D', 'Score_ED', 'Score_EG', 'Score_G', 'Score_Autre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in df.year.unique():\n",
    "    for dp in df.Departement.unique():\n",
    "        d = {}\n",
    "        for parti in df.Parti.unique():\n",
    "            try:\n",
    "                d[parti] = df[(df.year == year) & (df.Departement == dp) & (df.Parti == parti)].Score.values[0]\n",
    "            except IndexError:\n",
    "                d[parti] = 0\n",
    "        row = np.array([[year, dp, d['C'], d['D'], d['ED'], d['EG'], d['G'], d['Autre']]])\n",
    "        df2 = df2.append(pd.DataFrame(row,\n",
    "                                      columns=['year', 'dep', 'Score_C', 'Score_D', 'Score_ED', 'Score_EG', \n",
    "                                               'Score_G', 'Score_Autre']),\n",
    "                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ain', 'aisne', 'allier', 'alpes-de-haute-provence',\n",
       "       'alpes-maritimes', 'ardeche', 'ardennes', 'ariege', 'aube', 'aude',\n",
       "       'aveyron', 'bas-rhin', 'bouches-du-rhone', 'calvados', 'cantal',\n",
       "       'charente', 'charente-maritime', 'cher', 'correze', 'corse-du-sud',\n",
       "       'cote-d-or', 'creuse', 'deux-sevres', 'dordogne', 'doubs', 'drome',\n",
       "       'essonne', 'eure', 'eure-et-loir', 'finistere',\n",
       "       'francais-de-l-etranger', 'gard', 'gers', 'gironde', 'guadeloupe',\n",
       "       'guyane', 'haut-rhin', 'haute-corse', 'haute-garonne',\n",
       "       'haute-loire', 'haute-marne', 'haute-saone', 'haute-savoie',\n",
       "       'haute-vienne', 'hautes-alpes', 'hautes-pyrenees', 'hauts-de-seine',\n",
       "       'herault', 'ille-et-vilaine', 'indre', 'indre-et-loire', 'isere',\n",
       "       'jura', 'la-reunion', 'landes', 'loir-et-cher', 'loire',\n",
       "       'loire-atlantique', 'loiret', 'lot', 'lot-et-garonne', 'lozere',\n",
       "       'maine-et-loire', 'manche', 'marne', 'martinique', 'mayenne',\n",
       "       'mayotte', 'meurthe-et-moselle', 'meuse', 'morbihan', 'moselle',\n",
       "       'nievre', 'nord', 'nouvelle-caledonie', 'oise', 'orne', 'paris',\n",
       "       'pas-de-calais', 'polynesie-francaise', 'puy-de-dome',\n",
       "       'pyrenees-atlantiques', 'pyrenees-orientales', 'rhone',\n",
       "       'saint-pierre-et-miquelon', 'saone-et-loire', 'sarthe', 'savoie',\n",
       "       'seine-et-marne', 'seine-maritime', 'seine-saint-denis', 'somme',\n",
       "       'tarn', 'tarn-et-garonne', 'territoire-de-belfort', 'val-d-oise',\n",
       "       'val-de-marne', 'var', 'vaucluse', 'vendee', 'vienne', 'vosges',\n",
       "       'wallis-et-futuna', 'yonne', 'yvelines', 'cotes-d-armor',\n",
       "       'saint-martin-et-saint-barthelemy', 'Ain', 'Aisne', 'Allier',\n",
       "       'Alpes-Maritimes', 'Alpes-de-Haute-Provence', 'Ardennes',\n",
       "       'Ard\\xc3\\x83\\xc2\\xa8che', 'Ari\\xc3\\x83\\xc2\\xa8ge', 'Aube', 'Aude',\n",
       "       'Aveyron', 'Bas-Rhin', 'Bouches-du-Rh\\xc3\\x83\\xc2\\xb4ne',\n",
       "       'Calvados', 'Cantal', 'Charente', 'Charente-Maritime', 'Cher',\n",
       "       'Corr\\xc3\\x83\\xc2\\xa8ze', 'Corse-du-Sud', 'Creuse',\n",
       "       \"C\\xc3\\x83\\xc2\\xb4te-d'Or\", \"C\\xc3\\x83\\xc2\\xb4tes-d'Armor\",\n",
       "       'Deux-S\\xc3\\x83\\xc2\\xa8vres', 'Dordogne', 'Doubs',\n",
       "       'Dr\\xc3\\x83\\xc2\\xb4me', 'Essonne', 'Eure', 'Eure-et-Loir',\n",
       "       'Finist\\xc3\\x83\\xc2\\xa8re',\n",
       "       'Fran\\xc3\\x83\\xc2\\xa7ais \\xc3\\x83\\xc2\\xa9tablis hors de France',\n",
       "       'Gard', 'Gers', 'Gironde', 'Guadeloupe', 'Guyane', 'Haut-Rhin',\n",
       "       'Haute-Corse', 'Haute-Garonne', 'Haute-Loire', 'Haute-Marne',\n",
       "       'Haute-Savoie', 'Haute-Sa\\xc3\\x83\\xc2\\xb4ne', 'Haute-Vienne',\n",
       "       'Hautes-Alpes', 'Hautes-Pyr\\xc3\\x83\\xc2\\xa9n\\xc3\\x83\\xc2\\xa9es',\n",
       "       'Hauts-de-Seine', 'H\\xc3\\x83\\xc2\\xa9rault', 'Ille-et-Vilaine',\n",
       "       'Indre', 'Indre-et-Loire', 'Is\\xc3\\x83\\xc2\\xa8re', 'Jura',\n",
       "       'La R\\xc3\\x83\\xc2\\xa9union', 'Landes', 'Loir-et-Cher', 'Loire',\n",
       "       'Loire-Atlantique', 'Loiret', 'Lot', 'Lot-et-Garonne',\n",
       "       'Loz\\xc3\\x83\\xc2\\xa8re', 'Maine-et-Loire', 'Manche', 'Marne',\n",
       "       'Martinique', 'Mayenne', 'Mayotte', 'Meurthe-et-Moselle', 'Meuse',\n",
       "       'Morbihan', 'Moselle', 'Ni\\xc3\\x83\\xc2\\xa8vre', 'Nord',\n",
       "       'Nouvelle-Cal\\xc3\\x83\\xc2\\xa9donie', 'Oise', 'Orne', 'Paris',\n",
       "       'Pas-de-Calais',\n",
       "       'Polyn\\xc3\\x83\\xc2\\xa9sie fran\\xc3\\x83\\xc2\\xa7aise',\n",
       "       'Puy-de-D\\xc3\\x83\\xc2\\xb4me',\n",
       "       'Pyr\\xc3\\x83\\xc2\\xa9n\\xc3\\x83\\xc2\\xa9es-Atlantiques',\n",
       "       'Pyr\\xc3\\x83\\xc2\\xa9n\\xc3\\x83\\xc2\\xa9es-Orientales',\n",
       "       'Rh\\xc3\\x83\\xc2\\xb4ne',\n",
       "       'Saint-Martin/Saint-Barth\\xc3\\x83\\xc2\\xa9lemy',\n",
       "       'Saint-Pierre-et-Miquelon', 'Sarthe', 'Savoie',\n",
       "       'Sa\\xc3\\x83\\xc2\\xb4ne-et-Loire', 'Seine-Maritime',\n",
       "       'Seine-Saint-Denis', 'Seine-et-Marne', 'Somme', 'Tarn',\n",
       "       'Tarn-et-Garonne', 'Territoire de Belfort', \"Val-d'Oise\",\n",
       "       'Val-de-Marne', 'Var', 'Vaucluse', 'Vend\\xc3\\x83\\xc2\\xa9e',\n",
       "       'Vienne', 'Vosges', 'Wallis et Futuna', 'Yonne', 'Yvelines'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trop bien. On se débarasse des accents et autres saloperies ?\n",
    "#Hum en fait les saloperies viennent uniquement de ce que j'ai scrapé pour 2017. Traitement à la source possible ?\n",
    "\n",
    "#Pas de temps à perdre. Méthode barbare\n",
    "\n",
    "df2.dep.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>dep</th>\n",
       "      <th>Score_C</th>\n",
       "      <th>Score_D</th>\n",
       "      <th>Score_ED</th>\n",
       "      <th>Score_EG</th>\n",
       "      <th>Score_G</th>\n",
       "      <th>Score_Autre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Vienne</td>\n",
       "      <td>24.88</td>\n",
       "      <td>17.96</td>\n",
       "      <td>24.79</td>\n",
       "      <td>23.04</td>\n",
       "      <td>7.09</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Vosges</td>\n",
       "      <td>19.86</td>\n",
       "      <td>18.03</td>\n",
       "      <td>35.65</td>\n",
       "      <td>19.02</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Wallis et Futuna</td>\n",
       "      <td>30.48</td>\n",
       "      <td>28.53</td>\n",
       "      <td>8.59</td>\n",
       "      <td>5.37</td>\n",
       "      <td>25.22</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Yonne</td>\n",
       "      <td>19.63</td>\n",
       "      <td>19.91</td>\n",
       "      <td>34.84</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Yvelines</td>\n",
       "      <td>28.86</td>\n",
       "      <td>27.25</td>\n",
       "      <td>17.26</td>\n",
       "      <td>17.75</td>\n",
       "      <td>6.93</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year               dep Score_C Score_D Score_ED Score_EG Score_G  \\\n",
       "1279  2017.0            Vienne   24.88   17.96    24.79    23.04    7.09   \n",
       "1280  2017.0            Vosges   19.86   18.03    35.65    19.02    4.96   \n",
       "1281  2017.0  Wallis et Futuna   30.48   28.53     8.59     5.37   25.22   \n",
       "1282  2017.0             Yonne   19.63   19.91    34.84     18.6    4.79   \n",
       "1283  2017.0          Yvelines   28.86   27.25    17.26    17.75    6.93   \n",
       "\n",
       "     Score_Autre  \n",
       "1279        2.24  \n",
       "1280        2.47  \n",
       "1281        1.81  \n",
       "1282        2.22  \n",
       "1283        1.96  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico = {\"C\\xc3\\x83\\xc2\\xb4te-d'Or\": \"cote d'or\",\n",
    "       'Ari\\xc3\\x83\\xc2\\xa8ge': \"ariege\",\n",
    "       'Ard\\xc3\\x83\\xc2\\xa8che': 'ardeche',\n",
    "       'Bouches-du-Rh\\xc3\\x83\\xc2\\xb4ne': 'bouches-du-rhone',\n",
    "       'Corr\\xc3\\x83\\xc2\\xa8ze': 'correze',\n",
    "       ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VendAe'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "def rem_accents(s):\n",
    "    s2 = s.decode('utf-8')\n",
    "    nfkd_form = unicodedata.normalize('NFKD', s2)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii\n",
    "\n",
    "rem_accents(df2.dep.unique()[-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outpath = '/Users/Tom/python_projects/Memoire/Data/clean/clean_presid2.csv'\n",
    "df2.to_csv(outpath, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
